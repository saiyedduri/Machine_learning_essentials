{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "68abf705",
   "metadata": {},
   "source": [
    "# Difference between login node and compute node on a cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8813e52",
   "metadata": {},
   "source": [
    "| Feature       | Login Node | Compute Node |\n",
    "|--------------|-----------|-------------|\n",
    "| Purpose      | User interaction, job submission, file management | Running computational jobs.Compute nodes are used HPC calculations on cluster through a job script|\n",
    "| Accessibility | Direct user access via SSH | Accessed via job scheduler like Portable Batch management System(PBS) |\n",
    "| Resources    | Limited CPU, memory | High-performance CPUs, GPUs, memory |\n",
    "| Multi-user   | Shared | Often exclusive to a job |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f6618ef",
   "metadata": {},
   "source": [
    "OpenMP:   \n",
    "OpenMP (Open Multi-Processing) is a set of compiler directives and runtime functions that allow you to write parallel code easily in C, C++, and Fortran. It enables shared-memory multiprocessing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "158d6238",
   "metadata": {},
   "source": [
    "## Code for change_present working directory in Job script to cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c96b785",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "#PBS -N first-example \n",
    "#PBS -q teachingq  \n",
    "#PBS -l select=1:ncpus=1:mpiprocs=1 \n",
    "#PBS -l walltime=00:01:00  \n",
    "#PBS -o log.out  \n",
    "#PBS -e log.err  \n",
    "echo -e \"Job started from $(pwd)\"  \n",
    "echo \"Changing directory to...\"  \n",
    "PBS_O_WORKDIR=~/parllel_computing/  \n",
    "cd $PBS_O_WORKDIR  \n",
    "echo -e \"$(pwd)\"  \n",
    "cat my_file  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b378a14b",
   "metadata": {},
   "source": [
    "# Command for submitting a job script to cluster\n",
    "qsub job.script"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4059af86",
   "metadata": {},
   "source": [
    "PBS would assign job id. Ex: \n",
    "(base) [sy37tovi@mlogin01 parllel_computing]$ qsub change_pwd_cluster\n",
    "927540.mmaster02"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b7133b6",
   "metadata": {},
   "source": [
    "qstat will show running jobs. qdel <job-id> will delete a\n",
    "specific job that is currently running (status R) or waiting (status Q)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68958413",
   "metadata": {},
   "source": [
    "Status of  job script:\n",
    "| Job ID          | Name           | User      | Time Use | S | Queue      |\n",
    "|-----------------|----------------|-----------|----------|---|------------|\n",
    "| 929936.mmaster02| first-example  | sy37tovi  |        0 | R | teachingq  |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75fcd503",
   "metadata": {},
   "source": [
    "| S | Meaning   | Description                                                               |\n",
    "|------|-----------|---------------------------------------------------------------------------|\n",
    "| Q    | Queued    | Job is waiting in the queue to be scheduled.                             |\n",
    "| R    | Running   | Job is currently running on compute nodes.                               |\n",
    "| C    | Completed | Job has finished running (you might see this only briefly or in logs).   |\n",
    "| E    | Exiting   | Job is in the process of ending (wrapping up, cleaning up output, etc).  |\n",
    "| H    | Held      | Job is being held and won't be scheduled until released.                 |\n",
    "| S    | Suspended | Job has been suspended (paused) â€” usually by an admin or scheduler.      |\n",
    "| W    | Waiting   | Job is waiting for its start time (e.g., a scheduled future run).        |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06d05b3c",
   "metadata": {},
   "source": [
    "# Difference between shared memory and distributed memory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc05bc92",
   "metadata": {},
   "source": [
    "| Feature          | Shared Memory | Distributed Memory |\n",
    "|-----------------|--------------|-------------------|\n",
    "| **Definition**   | All processors access a common memory space. | Each processor has its own local memory. |\n",
    "| **Communication** | Data is shared through global memory. | Processors communicate via message passing (e.g., MPI). |\n",
    "| **Programming Model** | OpenMP, Pthreads | MPI (Message Passing Interface) |\n",
    "| **Scalability**  | Limited by memory bandwidth and bus speed. | Scales well across multiple nodes. |\n",
    "| **Performance**  | Fast communication but limited scalability. | Higher latency due to network communication. |\n",
    "| **Hardware Example** | Multi-core CPUs, SMP (Symmetric Multiprocessing) systems. | Cluster of computers, supercomputers. |\n",
    "| **Best For** | Programs running on a single machine with multiple cores. | Large-scale parallel computing across multiple nodes. |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88303cbc",
   "metadata": {},
   "source": [
    "# C code for open mpi example(open_mpi.c):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e46f6ce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#include <stdio.h>\n",
    "#include <omp.h>\n",
    "\n",
    "int main(int argc, char** argv){\n",
    "\n",
    "\t#pragma omp parallel\n",
    "\t{\n",
    "\t\tint numthreads,num;\n",
    "\t\tnumthreads=omp_get_num_threads();\n",
    "\t\tnum=omp_get_thread_num();\n",
    "        printf(\"Hello from thread %d of %d\\n\", num, numthreads);\n",
    "\t}\n",
    "\treturn 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8c77ea0",
   "metadata": {},
   "source": [
    "Compilation command:gcc -o output.bin open_mpi.c -O0 -fopenmp\n",
    "\n",
    "| **Part**              | **Meaning**                                               |\n",
    "|-----------------------|-----------------------------------------------------------|\n",
    "| `gcc`                 | Calls the GNU C compiler.                                 |\n",
    "| `-o hello-openmp.bin` | Specifies the output file name as `hello-openmp.bin`.      |\n",
    "| `main.c`              | The source file to compile.                               |\n",
    "| `-O0`                 | Disables optimizations (useful for debugging).            |\n",
    "| `-fopenmp`            | Enables OpenMP support for parallel programming.          |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4a553c2",
   "metadata": {},
   "source": [
    "Understanding Nodes, CPUs, and Threads:\n",
    "Node: A node is a machine or a computer in a cluster that usually has multiple CPU cores.\n",
    "\n",
    "CPU/Core: This is a single processing unit inside a node. Typically, each core can run one thread at a time.\n",
    "\n",
    "Thread: This is a unit of execution within a program. In OpenMP, threads are typically created within a process, and each thread can be mapped to a separate core."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcf8eee8",
   "metadata": {},
   "source": [
    "# Job script(job_script_4threads) to execute the shell script for executing the output in cluster in 'open_mp_example' directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "806133d4",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "#PBS -N first-example\n",
    "#PBS -q teachingq\n",
    "#PBS -l select=1:ncpus=4:mpiprocs=1\n",
    "#PBS -l walltime=00:01:00\n",
    "#PBS -o log.out1\n",
    "#PBS -e log.err1\n",
    "export OMP_NUM_THREADS=4\n",
    "\n",
    "echo -e \"Job started from $(pwd).\"\n",
    "echo \"Changing directory to...\"\n",
    "PBS_O_WORKDIR=/home/sy37tovi/parllel_computing/open_mp_example\n",
    "cd $PBS_O_WORKDIR\n",
    "echo -e \"$(pwd)\"\n",
    "\n",
    "./output.bin"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a39bf6f1",
   "metadata": {},
   "source": [
    "Job started from /home/sy37tovi/pbs.929936.mmaster02.x8z.\n",
    "Changing directory to...\n",
    "/home/sy37tovi/parllel_computing/open_mp_example\n",
    "Hello from thread 0 of 4\n",
    "Hello from thread 3 of 4\n",
    "Hello from thread 1 of 4\n",
    "Hello from thread 2 of 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01b74ed8",
   "metadata": {},
   "source": [
    "# C code example for identifying function/ usage of threads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6669f2bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#include <stdio.h>\n",
    "#include <omp.h>\n",
    "\n",
    "int main(int argc, char** argv){\n",
    "\n",
    "    int numthreads = omp_get_num_threads();\n",
    "    int num = omp_get_thread_num();\n",
    "\n",
    "    printf(\"Hello from the master thread %d of %d\\n\\n\", num, numthreads);\n",
    "\n",
    "    #pragma omp parallel\n",
    "    {\n",
    "        numthreads = omp_get_num_threads();\n",
    "        num = omp_get_thread_num();\n",
    "        printf(\"     Hello from the forked thread %d of %d\\n\", num, numthreads);\n",
    "    }\n",
    "\n",
    "    printf(\"\\nHello (again) from the master thread %d of %d\\n\", num, numthreads);\n",
    "\n",
    "    return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b557d57b",
   "metadata": {},
   "source": [
    " gcc -o output2.bin open_mpi2.c -O0 -fopenmp # Saves the compiled file as output2.bin"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0b45d2b",
   "metadata": {},
   "source": [
    "# Job script(job_script_4threads2) to execute the shell script for execting the output in 'open_mp_example' directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "593be7ca",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "#PBS -N first-example\n",
    "#PBS -q teachingq\n",
    "#PBS -l select=1:ncpus=4:mpiprocs=1\n",
    "#PBS -o log.out2\n",
    "#PBS -e log.err2\n",
    "export OMP_NUM_THREADS=4\n",
    "\n",
    "echo -e \"Job started from $(pwd).\"\n",
    "echo \"Changing directory to...\"\n",
    "PBS_O_WORKDIR=/home/sy37tovi/parllel_computing/open_mp_example\n",
    "cd $PBS_O_WORKDIR\n",
    "echo -e \"$(pwd)\"\n",
    "\n",
    "./output2.bin"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "639d0c50",
   "metadata": {},
   "source": [
    "int numthreads = omp_get_num_threads();\n",
    "int num = omp_get_thread_num();\n",
    "At this point, the program hasn't entered the parallel region yet. So:\n",
    "omp_get_num_threads() returns 1\n",
    "\n",
    "omp_get_thread_num() returns 0\n",
    "printf(\"Hello from the master thread %d of %d\\n\\n\", num, numthreads);\n",
    "Hello from the master thread 0 of 1\n",
    "\n",
    "In the #pragma omp parallel block, OpenMP forks multiple threads.\n",
    "\n",
    "Each thread will:\n",
    "\n",
    "Get its own thread number (omp_get_thread_num())\n",
    "\n",
    "Get total threads (omp_get_num_threads())\n",
    "\n",
    "Hello from the forked thread 0 of 4\n",
    "Hello from the forked thread 1 of 4\n",
    "Hello from the forked thread 2 of 4\n",
    "Hello from the forked thread 3 of 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f40557a",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "#PBS -N first-example \n",
    "#PBS -q teachingq  \n",
    "#PBS -l select=1:ncpus=1:mpiprocs=1 \n",
    "#PBS -l walltime=00:01:00  \n",
    "#PBS -o log.out  \n",
    "#PBS -e log.err  \n",
    "echo -e \"Job started from $(pwd)\"  \n",
    "echo \"Changing directory to...\"  \n",
    "PBS_O_WORKDIR=~/parllel_computing/  \n",
    "cd $PBS_O_WORKDIR  \n",
    "echo -e \"$(pwd)\"  \n",
    "cat my_file  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97782233",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "source": [
    "Command for submitting the job script:\n",
    " qsub job_script_4threads2\n",
    "\n",
    " After running, the output will be saved in log.out2 as mentioned in the job script\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73b928b6",
   "metadata": {},
   "source": [
    "Job started from /home/sy37tovi/pbs.929938.mmaster02.x8z.\n",
    "Changing directory to...\n",
    "/home/sy37tovi/parllel_computing/open_mp_example\n",
    "Hello from the master thread 0 of 1\n",
    "\n",
    "     Hello from the forked thread 0 of 4\n",
    "     Hello from the forked thread 2 of 4\n",
    "     Hello from the forked thread 1 of 4\n",
    "     Hello from the forked thread 3 of 4\n",
    "\n",
    "Hello (again) from the master thread 3 of 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "333a8eac",
   "metadata": {},
   "source": [
    "Here, this line:     \n",
    "printf(\"\\nHello (again) from the master thread %d of %d\\n\", num, numthreads);\n",
    "\n",
    "prints 3rd thread as master thread eventhough 0 is the master thread.\n",
    "\n",
    "By default, variables like num and numthreads are shared in OpenMP. So all threads are writing to the same memory â€” which leads to race conditions.\n",
    "\n",
    "We fix this by rewriting the c script by initiality the variables agaain after the parllel block."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2c17c81",
   "metadata": {},
   "outputs": [],
   "source": [
    "#include <stdio.h>\n",
    "#include <omp.h>\n",
    "\n",
    "int main(int argc, char** argv){\n",
    "\n",
    "    int numthreads = omp_get_num_threads();\n",
    "    int num = omp_get_thread_num();\n",
    "\n",
    "    printf(\"Hello from the master thread %d of %d\\n\\n\", num, numthreads);\n",
    "\n",
    "    #pragma omp parallel\n",
    "    {\n",
    "        numthreads = omp_get_num_threads();\n",
    "        num = omp_get_thread_num();\n",
    "        printf(\"     Hello from the forked thread %d of %d\\n\", num, numthreads);\n",
    "    }\n",
    "\n",
    "    // FIX: Recomputing these values after parallel section to get the master thread\n",
    "    numthreads = omp_get_num_threads();\n",
    "    num = omp_get_thread_num();\n",
    "    printf(\"\\nHello (again) from the master thread %d of %d\\n\", num, numthreads);\n",
    "\n",
    "    return 0;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "691fb33d",
   "metadata": {},
   "source": [
    "Now the output is: \n",
    "Job started from /home/sy37tovi/pbs.929983.mmaster02.x8z.\n",
    "Changing directory to...\n",
    "/home/sy37tovi/parllel_computing/open_mp_example\n",
    "Hello from the master thread 0 of 1\n",
    "\n",
    "     Hello from the forked thread 0 of 4\n",
    "     Hello from the forked thread 1 of 4\n",
    "     Hello from the forked thread 3 of 4\n",
    "     Hello from the forked thread 2 of 4\n",
    "\n",
    "Hello (again) from the master thread 0 of 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f7699c0",
   "metadata": {},
   "source": [
    "# omp parllel private(num)\n",
    "#pragma omp parallel\n",
    "This tells the compiler to create a parallel region â€” meaning multiple threads will execute the block of code that follows.\n",
    "\n",
    "private(num)\n",
    "This clause declares that the variable num is private to each thread. That means:\n",
    "\n",
    "Each thread gets its own uninitialized copy of num.\n",
    "\n",
    "Modifications to num by one thread do not affect the value of num seen by other threads.\n",
    "\n",
    "The original value of num (before the parallel region) is not visible to threads inside the parallel region.\n",
    "\n",
    "The modified value of num inside the parallel region is not preserved after the parallel region ends.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f7a3456",
   "metadata": {},
   "source": [
    "# omp parllel for partioning/assigning the iterations for different threads\n",
    "\n",
    "If we run the for loop in the parllel block then n iterations happen for each threads, which might be redundant in most of the cases. With omp parllel for, we can avoid this by assigning different iterations to threads running parllely"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a09c8c85",
   "metadata": {},
   "outputs": [],
   "source": [
    "#include <stdio.h>\n",
    "#include <omp.h>\n",
    "\n",
    "int main(int argc, char** argv) {\n",
    "    int i;\n",
    "    int N = 10;\n",
    "\n",
    "    #pragma omp parallel for\n",
    "    for (i = 0; i < N; i++) {\n",
    "        int num = omp_get_thread_num();\n",
    "        printf(\"Thread %d does iteration %d\\n\", num, i);\n",
    "    }\n",
    "    return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2419c5bf",
   "metadata": {},
   "source": [
    "Compilation command: gcc -o output2.bin open_mp_parllel_for.c -O0 -fopenmp\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91e62f13",
   "metadata": {},
   "source": [
    "output:\n",
    "\n",
    "Job started from /home/sy37tovi/pbs.932784.mmaster02.x8z.\n",
    "\n",
    "Changing directory to...\n",
    "\n",
    "/home/sy37tovi/parllel_computing/open_mp_for_loop\n",
    "\n",
    "Thread 0 does iteration 0\n",
    "\n",
    "Thread 0 does iteration 1\n",
    "\n",
    "Thread 0 does iteration 2\n",
    "\n",
    "Thread 2 does iteration 6\n",
    "\n",
    "Thread 2 does iteration 7\n",
    "\n",
    "Thread 3 does iteration 8\n",
    "\n",
    "Thread 3 does iteration 9\n",
    "\n",
    "Thread 1 does iteration 3\n",
    "\n",
    "Thread 1 does iteration 4\n",
    "\n",
    "Thread 1 does iteration 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "812ad0fa",
   "metadata": {},
   "source": [
    "# Scheduling the parllel computing in for loop  through static, dynamic and runtime \n",
    "Present in: /parllel_computing/open_mp_for_loop/scheduling folder :\n",
    "\n",
    "In openmp, scheduling controls how loop iterations are divided among threads in a parllel for loop.\n",
    "\n",
    "Why is scheduling important?\n",
    "Different types of work may take different time per iteration, so a bad schedule might lead to:\n",
    "\n",
    "Some threads finishing early and sitting idle.\n",
    "\n",
    "Unbalanced load â†’ reduced performance.\n",
    "\n",
    "| **Schedule Type** | **How it Works**                                                                 |\n",
    "|-------------------|-----------------------------------------------------------------------------------|\n",
    "| `static`          | Iterations are divided evenly before the loop starts. Fast but rigid.            |\n",
    "| `dynamic`         | Threads grab chunks of iterations as they finish work. Better for load balancing.|\n",
    "| `guided`          | Like dynamic, but chunk sizes shrink over time. Good for decreasing workloads.   |\n",
    "| `auto`            | Lets the compiler/runtime decide the best scheduling strategy.                   |\n",
    "| `runtime`         | Uses the `OMP_SCHEDULE` environment variable to decide at runtime.               |\n",
    "\n",
    "By default, omp parllel for assumed as 'static'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de017e15",
   "metadata": {},
   "source": [
    "What is the difference betweeen\n",
    "\n",
    "â€“ schedule(static,1),\n",
    "\n",
    "â€“ schedule(dynamic), and\n",
    "\n",
    "â€“ schedule(dynamic,3)?\n",
    "\n",
    "\n",
    "schedule(static,1):\n",
    "    Static schedule â†’ iterations are divided upfront among threads in a round-robin fashion.\n",
    "\n",
    "    Chunk size = 1 â†’ each thread gets one iteration at a time, but assignments are pre-determined.\n",
    "\n",
    "    Example (4 threads, 8 iterations):\n",
    "\n",
    "    Thread\tIterations\n",
    "\n",
    "    0\t    0, 4\n",
    "\n",
    "    1\t    1, 5\n",
    "\n",
    "    2\t    2, 6\n",
    "\n",
    "    3\t    3, 7\n",
    "\n",
    "schedule(dynamic):\n",
    "\n",
    "    Threads ask for work as they finish.\n",
    "\n",
    "    Default chunk size (usually 1 if not specified).\n",
    "\n",
    "    Best when workload per iteration is unpredictable.\n",
    "\n",
    "    Example (dynamic load balancing):\n",
    "    Thread 0 finishes early â†’ asks for more iterations. No fixed assignment like in static.\n",
    "\n",
    "schedule(dynamic,3):\n",
    "\n",
    "    Threads ask for work as they finish\n",
    "\n",
    "    Threads grab 3 iterations at a time (called a chunk).\n",
    "    Behavior:\n",
    "        Thread 0 grabs 0â€“2\n",
    "\n",
    "        Thread 1 grabs 3â€“5\n",
    "\n",
    "        Thread 2 grabs 6â€“8\n",
    "\n",
    "        And so on...\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bca0b36",
   "metadata": {},
   "source": [
    "# Example: Montecarlo simulation algorithm for open mp reduction and thread safety"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf014ffa",
   "metadata": {},
   "source": [
    "Montecarlo simulation is a statistical technique used to understand the impact of risk and uncertainty in mathematical models and decision-making. It works by using random sampling and running many simulations to estimate results by taking average of those results.\n",
    "\n",
    "Instead of solving a problem analytically, we simulate the problem many times with random inputs and look at the average outcome.\n",
    "\n",
    "# Idea behind the montecarlo simulation:\n",
    "The program estimates the value of Ï€ using a Monte Carlo method.\n",
    "\n",
    "Imagine a square with side length 1.\n",
    "\n",
    "Inside the square, fit a quarter circle of radius 1 (from (0,0) to (1,1)).\n",
    "\n",
    "Randomly throw points inside the square.\n",
    "\n",
    "The ratio of points inside the circle to total points approximates the area of the quarter circle.\n",
    "\n",
    "Since:\n",
    "\n",
    "Area of quarter circle = (Ï€ * rÂ²) / 4 = Ï€ / 4\n",
    "\n",
    "Area of square = 1\n",
    "\n",
    "Then:\n",
    "\n",
    "Ï€ â‰ˆ 4 Ã— (number of points inside circle / total number of points)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41c94519",
   "metadata": {},
   "outputs": [],
   "source": [
    "#include <stdio.h>\n",
    "#include <stdlib.h>\n",
    "\n",
    "int main(int argc, char** argv){\n",
    "        unsigned int i,hit=0;\n",
    "        unsigned int simulations;\n",
    "\n",
    "        if (argc<2 || atoi(argv[1])<=0){\n",
    "                 printf(\"Usage: ./<exe> <unsigned int = problem size>\\n\");  \n",
    "                simulations=10;\n",
    "        }else {\n",
    "                simulations=atoi(argv[1]);\n",
    "        }\n",
    "        double x,y;\n",
    "\n",
    "        #pragma omp parllel for private(x,y) reduction(+:hit)\n",
    "        for(i=0; i<simulations;i++)\n",
    "        {\n",
    "                x = ((double)rand_r())/RAND_MAX;\n",
    "                y = ((double)rand_r())/RAND_MAX;\n",
    "                if ((x*x)+(y*y)<=1){\n",
    "                        hit++;\n",
    "                }\n",
    "        }\n",
    "        printf(\"Pi=%16.16f\\n\",(4.0*hit)/simulations);\n",
    "        return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10d36447",
   "metadata": {},
   "source": [
    "reduction(+:hit)\n",
    "hit is being incremented (hit++) inside the loop.\n",
    "\n",
    "If multiple threads tried to increment the same hit variable at once, you'd get incorrect results (race condition).\n",
    "\n",
    "reduction(+:hit) means:\n",
    "\n",
    "Each thread gets its own local copy of hit, initialized to 0.\n",
    "\n",
    "After the loop, OpenMP adds up all the local hits into the shared/global hit variable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0fe81b0",
   "metadata": {},
   "source": [
    "# Jobscript for montecarlo.c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2d8ec79",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "#PBS -N first-example\n",
    "#PBS -q teachingq\n",
    "#PBS -l select=1:ncpus=4:mpiprocs=1\n",
    "#PBS -l walltime=00:01:00\n",
    "#PBS -o log.out1\n",
    "#PBS -e log.err1\n",
    "export OMP_NUM_THREADS=4\n",
    "\n",
    "echo -e \"Job started from $(pwd).\"\n",
    "echo \"Changing directory to...\"\n",
    "PBS_O_WORKDIR=/home/sy37tovi/parllel_computing/montecarlo_parllel_computing\n",
    "cd $PBS_O_WORKDIR\n",
    "echo -e \"$(pwd)\"\n",
    "\n",
    "./montecarlo.bin 400000000 // executing with 400000000 simulations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ead3b7e",
   "metadata": {},
   "source": [
    "# Strong scaling test:\n",
    "\n",
    "A strong scaling test measures how the performance of a parallel program improves when you increase the number of processors (threads/cores) while keeping the problem size fixed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "753455cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6819f29f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
